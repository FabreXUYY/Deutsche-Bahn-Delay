{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24634090",
   "metadata": {},
   "source": [
    "Group Name   : Lucid_Jespen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91df70",
   "metadata": {},
   "source": [
    "Members      : Xiao SHEN, Yuanye XU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c657c8",
   "metadata": {},
   "source": [
    "Project Name : Delay Rate of DB 20-25.07.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00152a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"trains_db_hbfs.csv\")\n",
    "\n",
    "\n",
    "# make data buckets for scheduled time by hour\n",
    "df['scheduled_time'] = pd.to_datetime(df['scheduled_time'], errors='coerce')\n",
    "df['hour_bucket'] = df['scheduled_time'].dt.hour\n",
    "\n",
    "\n",
    "# fill in column departure_city by removing 'hbf' and space in column Hbf\n",
    "if 'Hbf' in df.columns:\n",
    "    df['departure_city'] = df['Hbf'].astype(str).str.replace(r'Hbf\\s*$', '', regex=True).str.strip()\n",
    "else:\n",
    "    print(\"Warning: Cannot find column 'Hbf' \")\n",
    "\n",
    "\n",
    "# eg. route: someplace,sometime ; train_model: AB 123\n",
    "# create columns route_cleaned and train_model_cleaned by removing numbers\n",
    "if 'route' in df.columns:\n",
    "    df['route_cleaned'] = df['route'].astype(str).str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "else:\n",
    "    print(\"Warning: Cannot find 'route'\")\n",
    "\n",
    "if 'train_model' in df.columns:\n",
    "    df['train_model_cleaned'] = df['train_model'].astype(str).str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "else:\n",
    "    print(\"Warning: Cannot find 'train_model'\")\n",
    "\n",
    "\n",
    "# clean \",:\" in the end of route_cleaned \n",
    "if 'route_cleaned' in df.columns:\n",
    "    df['route_cleaned'] = (\n",
    "        df['route_cleaned']\n",
    "        .astype(str)\n",
    "        .str.replace(r'[:,]+$', '', regex=True)  \n",
    "        .str.strip()\n",
    "    )\n",
    "else:\n",
    "    print(\"Warning: Cannot find 'route_cleaned'\")\n",
    "\n",
    "# clean \"()\" in the end of train_model_cleaned\n",
    "if 'train_model_cleaned' in df.columns:\n",
    "    df['train_model_cleaned'] = (\n",
    "        df['train_model_cleaned']\n",
    "        .astype(str)\n",
    "        .str.replace(r'\\(\\s*\\)$', '', regex=True)  \n",
    "        .str.strip()\n",
    "    )\n",
    "else:\n",
    "    print(\"Warning: Cannot find 'train_model_cleaned'\")\n",
    "\n",
    "\n",
    "# eg. real_time_due_to_delay: 13.05, Grund: Gleiswechseln\n",
    "# keep time in the column, move causes to another column\n",
    "if 'real_time_due_to_delay' in df.columns:\n",
    "    split_real = df['real_time_due_to_delay'].astype(str).str.split(',', n=1, expand=True)\n",
    "\n",
    "    df['real_time_due_to_delay'] = split_real[0].str.strip()\n",
    "\n",
    "    if split_real.shape[1] > 1:\n",
    "        df['causes'] = split_real.iloc[:, 1].str.strip()\n",
    "    else:\n",
    "        df['causes'] = np.nan\n",
    "else:\n",
    "    print(\" Warning: cannot find 'real_time_due_to_delay'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate delay time\n",
    "\n",
    "# transform time into datetime\n",
    "df['real_time_due_to_delay'] = pd.to_datetime(df['real_time_due_to_delay'], errors='coerce').dt.time\n",
    "df['expected_time'] = pd.to_datetime(df['expected_time'], errors='coerce').dt.time\n",
    "\n",
    "# time into min, make calculation easier\n",
    "def time_to_minutes(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    return t.hour * 60 + t.minute\n",
    "\n",
    "df['real_minutes'] = df['real_time_due_to_delay'].apply(time_to_minutes)\n",
    "df['expected_minutes'] = df['expected_time'].apply(time_to_minutes)\n",
    "\n",
    "# calculate delay time(min) by real arrival time - expected arrival time\n",
    "def calculate_delay(row):\n",
    "    if pd.isna(row['real_minutes']) or pd.isna(row['expected_minutes']):\n",
    "        return None\n",
    "    delay = row['real_minutes'] - row['expected_minutes']\n",
    "    if delay < 0:\n",
    "        delay += 24 * 60  # if delay < 0 : arriving on the next day, + 24h\n",
    "    return delay\n",
    "\n",
    "df['real_delay_min'] = df.apply(calculate_delay, axis=1)\n",
    "df.drop(columns=['real_minutes', 'expected_minutes'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# return arrival city by station name\n",
    "cache = {}\n",
    "def get_city_from_station(station):\n",
    "    if station in cache:\n",
    "        return cache[station]\n",
    "    try:\n",
    "        location = geolocator.geocode(station + \", Germany\")\n",
    "        if location:\n",
    "            city = location.address.split(\",\")[-4].strip()\n",
    "            cache[station] = city\n",
    "            return city\n",
    "    except:\n",
    "        return None\n",
    "geolocator = Nominatim(user_agent=\"db_station_locator\")\n",
    "\n",
    "df[\"city\"] = None\n",
    "\n",
    "for i, s in df[\"route_cleaned\"].items():\n",
    "    if pd.notna(s):\n",
    "        df.loc[i, \"city\"] = get_city_from_station(s)\n",
    "        print(df.loc[i, \"city\"])\n",
    "        #time.sleep(0.5)   \n",
    "\n",
    "df.to_csv(\"trains_db_wash_1.csv\", index=False)\n",
    "print(\"new document created：trains_db_wash_1.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c791a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_punctuality.py\n",
    "# This script trains a RandomForestClassifier to predict punctuality (is_punctual = 1 for on-time)\n",
    "# It uses the same train/test split (random_state=42, stratify by target) so results are directly\n",
    "# comparable to a Logistic Regression baseline trained with the same split.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_PATH = r\"E:\\3model.xlsx\"      # change to your file path\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "N_ESTIMATORS = 200\n",
    "OUTPUT_CM = \"./rf_confusion_matrix.png\"\n",
    "OUTPUT_IMPORTANCES = \"./rf_feature_importances.csv\"\n",
    "# ----------------------------\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "\n",
    "# 1) Load data\n",
    "df = pd.read_excel(INPUT_PATH)\n",
    "\n",
    "# 2) clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3) ensure punctuality target column exists\n",
    "# If you have only 'has_delay' (1 = delayed, 0 = on-time), create is_punctual = 1 - has_delay\n",
    "if \"is_punctual\" not in df.columns:\n",
    "    if \"has_delay\" in df.columns:\n",
    "        df[\"is_punctual\"] = 1 - df[\"has_delay\"]\n",
    "    else:\n",
    "        raise KeyError(\"No 'is_punctual' or 'has_delay' column found in the input file.\")\n",
    "\n",
    "# 4) Define features and target\n",
    "features = [\"Hbf\", \"arrive_station\", \"train_category\", \"depart_hour_bucket\"]\n",
    "target = \"is_punctual\"\n",
    "\n",
    "# sanity check\n",
    "for col in features + [target]:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {col} in the input file\")\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# 5) Create train/test split ONCE so it matches the one used for logistic regression baseline\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 6) Build OneHotEncoder with compatibility for different sklearn versions\n",
    "# newer sklearn (>=1.2) uses sparse_output, older uses sparse\n",
    "ohe_kwargs = {\"handle_unknown\": \"ignore\"}\n",
    "try:\n",
    "    # try the newer parameter name\n",
    "    enc = OneHotEncoder(**ohe_kwargs, sparse_output=False)\n",
    "except TypeError:\n",
    "    # fall back to older parameter name\n",
    "    enc = OneHotEncoder(**ohe_kwargs, sparse=False)\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[(\"cat\", enc, features)],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False  # keep feature names clean if supported\n",
    ")\n",
    "\n",
    "# 7) Fit encoder on training raw data and transform both train and test\n",
    "# We fit the encoder only on train to avoid leakage\n",
    "column_transformer.fit(X_train_raw)\n",
    "X_train = column_transformer.transform(X_train_raw)\n",
    "X_test = column_transformer.transform(X_test_raw)\n",
    "\n",
    "# 8) Train Random Forest on encoded features\n",
    "rf = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 9) Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# 10) Plot and save confusion matrix (labels: Delay=0, On-time=1)\n",
    "labels = [\"Delay (0)\", \"On-time (1)\"]\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(\"Random Forest Confusion Matrix (Punctuality Prediction)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_CM, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved confusion matrix to {os.path.abspath(OUTPUT_CM)}\")\n",
    "\n",
    "# 11) Map feature importances back to one-hot feature names\n",
    "# get feature names from the fitted OneHotEncoder\n",
    "ohe = column_transformer.named_transformers_[\"cat\"]\n",
    "try:\n",
    "    feature_names = ohe.get_feature_names_out(features)\n",
    "except Exception:\n",
    "    # fallback: manually build feature names\n",
    "    categories = ohe.categories_\n",
    "    feature_names = []\n",
    "    for col, cats in zip(features, categories):\n",
    "        feature_names += [f\"{col}__{str(c)}\" for c in cats]\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "if len(feature_names) != len(importances):\n",
    "    print(\"Warning: feature names length does not match importances length.\")\n",
    "# create dataframe of importances\n",
    "imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "imp_df = imp_df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "imp_df.to_csv(OUTPUT_IMPORTANCES, index=False)\n",
    "print(f\"Saved feature importances to {os.path.abspath(OUTPUT_IMPORTANCES)}\")\n",
    "\n",
    "# 12) Optional: plot top 30 importances\n",
    "top_k = 30\n",
    "plt.figure(figsize=(8, max(4, 0.25 * min(top_k, len(imp_df)))))\n",
    "imp_df.head(top_k).sort_values(\"importance\").plot.barh(x=\"feature\", y=\"importance\", legend=False, color=\"skyblue\")\n",
    "plt.title(\"Top feature importances (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./rf_top_importances.png\", dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved top feature importances plot to {os.path.abspath('./rf_top_importances.png')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52324781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logreg_punctuality.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_PATH = r\"E:\\3model.xlsx\"\n",
    "OUTPUT_IMAGE = r\"./confusion_matrix.png\"\n",
    "OUTPUT_COEF_CSV = r\"./logreg_feature_coefs.csv\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "# ----------------------------\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_excel(INPUT_PATH)\n",
    "\n",
    "# 2. Ensure target column 'is_punctual' exists (1 = on-time, 0 = delay)\n",
    "# If your file only has 'has_delay' (1 = delay, 0 = on-time), create is_punctual = 1 - has_delay\n",
    "if \"is_punctual\" not in df.columns:\n",
    "    if \"has_delay\" in df.columns:\n",
    "        df[\"is_punctual\"] = 1 - df[\"has_delay\"]\n",
    "    else:\n",
    "        raise KeyError(\"No 'is_punctual' or 'has_delay' column found in the input file.\")\n",
    "\n",
    "# 3. Define features and target\n",
    "features = [\"Hbf\", \"arrive_station\", \"train_category\", \"depart_hour_bucket\"]\n",
    "target = \"is_punctual\"\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# 4. Build column transformer with OneHotEncoder for categorical columns\n",
    "# handle_unknown='ignore' prevents errors when test set contains unseen categories\n",
    "cat_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), features)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False  # available in newer sklearn; keeps names clean\n",
    ")\n",
    "\n",
    "# 5. Build pipeline: encoder -> classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"encoder\", cat_transformer),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# 6. Train-test split (randomly mix July and September data to reduce seasonality bias)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 7. Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 8. Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# 9. Plot and save confusion matrix\n",
    "labels = [\"Delay (0)\", \"On-time (1)\"]\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression (Punctuality Prediction)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_IMAGE, dpi=300)\n",
    "plt.close()\n",
    "print(f\"\\nSaved confusion matrix to {os.path.abspath(OUTPUT_IMAGE)}\")\n",
    "\n",
    "# 10. Extract one-hot feature names and coefficients, then save to CSV\n",
    "# Get the fitted OneHotEncoder from the pipeline\n",
    "ohe = pipeline.named_steps[\"encoder\"].named_transformers_[\"cat\"]\n",
    "# sklearn >=1.0: use get_feature_names_out\n",
    "try:\n",
    "    feat_names = ohe.get_feature_names_out(features)\n",
    "except AttributeError:\n",
    "    # fallback: construct names manually\n",
    "    categories = ohe.categories_\n",
    "    feat_names = []\n",
    "    for col, cats in zip(features, categories):\n",
    "        feat_names += [f\"{col}__{str(c)}\" for c in cats]\n",
    "\n",
    "# Get coefficients from the logistic regression step\n",
    "coefs = pipeline.named_steps[\"clf\"].coef_[0]\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"coefficient\": coefs\n",
    "}).sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
    "\n",
    "coef_df.to_csv(OUTPUT_COEF_CSV, index=False)\n",
    "print(f\"Saved logistic regression feature coefficients to {os.path.abspath(OUTPUT_COEF_CSV)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Visualization and Descriptive Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1️⃣ Load the dataset\n",
    "df = pd.read_excel(r\"E:\\3model.xlsx\")\n",
    "\n",
    "# 2️⃣ Verify that essential columns exist\n",
    "required_cols = [\"depart_hour_bucket\", \"train_category\", \"has_delay\"]\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {col}\")\n",
    "\n",
    "# 3️⃣ Calculate hourly on-time rates (1 - delay rate)\n",
    "on_time_by_hour = (1 - df.groupby(\"depart_hour_bucket\")[\"has_delay\"].mean()) * 100\n",
    "print(\"Hourly Punctuality Rate (%):\")\n",
    "print(on_time_by_hour.round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4️⃣ Calculate on-time rates by train category\n",
    "on_time_by_type = (1 - df.groupby(\"train_category\")[\"has_delay\"].mean()) * 100\n",
    "print(\"Punctuality Rate by Train Category (%):\")\n",
    "print(on_time_by_type.round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5️⃣ Create a pivot table for hour × category on-time rates\n",
    "pivot_on_time = (1 - pd.pivot_table(\n",
    "    df,\n",
    "    values=\"has_delay\",\n",
    "    index=\"depart_hour_bucket\",\n",
    "    columns=\"train_category\",\n",
    "    aggfunc=\"mean\"\n",
    ")) * 100\n",
    "print(\"Punctuality Rate by Hour × Train Category (%):\")\n",
    "print(pivot_on_time.round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6️⃣ Plot hourly on-time rate (line chart)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(on_time_by_hour.index, on_time_by_hour.values, marker='o', color='seagreen')\n",
    "plt.title(\"Train Punctuality by Hour\", fontsize=14)\n",
    "plt.xlabel(\"Hour of the Day (1–24)\")\n",
    "plt.ylabel(\"Punctuality Rate (%)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.xticks(range(0, 25, 2))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7️⃣ Plot on-time rate by train category (bar chart)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(on_time_by_type.index, on_time_by_type.values, color=['teal', 'orange', 'tomato'])\n",
    "plt.title(\"Average Punctuality by Train Category\", fontsize=14)\n",
    "plt.xlabel(\"Train Category\")\n",
    "plt.ylabel(\"Punctuality (%)\")\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_model_same_split.py\n",
    "\"\"\"\n",
    "Train multiple models using the exact same train/test split (random split).\n",
    "Target is 'is_punctual' (1 = on-time). If original file has 'has_delay' (1=delay),\n",
    "the script creates is_punctual = 1 - has_delay.\n",
    "\n",
    "LogisticRegression uses OneHotEncoder (fit on X_train only).\n",
    "Tree models (RandomForest, LightGBM, optional XGBoost) use integer label mapping.\n",
    "All models use the same train/test rows to ensure fair comparison.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Optional boosters\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Please install lightgbm: pip install lightgbm\") from e\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FILE_PATH = r\"E:\\3model.xlsx\"   # change to your path\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "FEATURES = [\"Hbf\", \"arrive_station\", \"train_category\", \"depart_hour_bucket\"]\n",
    "ORIG_TARGET = \"has_delay\"   # if present, 1=delay\n",
    "TARGET = \"is_punctual\"      # 1 = on-time\n",
    "# ----------------------------------------\n",
    "\n",
    "# 1) load data\n",
    "df = pd.read_excel(FILE_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 2) build target\n",
    "if TARGET not in df.columns:\n",
    "    if ORIG_TARGET in df.columns:\n",
    "        df[TARGET] = 1 - df[ORIG_TARGET].astype(int)\n",
    "        print(\"Created 'is_punctual' from 'has_delay'\")\n",
    "    else:\n",
    "        raise KeyError(\"Provide 'has_delay' (1=delay) or 'is_punctual' in the input file.\")\n",
    "\n",
    "# 3) basic cleaning for categorical columns\n",
    "for c in FEATURES:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing feature column: {c}\")\n",
    "    df[c] = df[c].astype(str).str.strip().fillna(\"MISSING\")\n",
    "\n",
    "# 4) Compose dataset to use for splitting\n",
    "#    If you want only July+Sept rows, filter first; otherwise use full df.\n",
    "#    Example: filter to July+Sept (uncomment and adapt column name if you have a date column)\n",
    "# date_col = \"date\"  # change if applicable\n",
    "# df = df[df[date_col].dt.month.isin([7,9])]\n",
    "\n",
    "X_full = df[FEATURES].copy()\n",
    "y_full = df[TARGET].astype(int).copy()\n",
    "\n",
    "# 5) single random split used for all models\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_full, y_full, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_full\n",
    ")\n",
    "print(f\"Train rows: {len(X_train_raw)}, Test rows: {len(X_test_raw)}\")\n",
    "\n",
    "# 6) Prepare OneHot for Logistic Regression (fit on training rows only)\n",
    "ohe_kwargs = {\"handle_unknown\": \"ignore\"}\n",
    "try:\n",
    "    encoder = OneHotEncoder(**ohe_kwargs, sparse_output=False)\n",
    "except TypeError:\n",
    "    encoder = OneHotEncoder(**ohe_kwargs, sparse=False)\n",
    "\n",
    "ohe_cols = FEATURES  # treat all features as categorical for logistic model\n",
    "encoder.fit(X_train_raw[ohe_cols])\n",
    "X_train_ohe = encoder.transform(X_train_raw[ohe_cols])\n",
    "X_test_ohe  = encoder.transform(X_test_raw[ohe_cols])\n",
    "\n",
    "# 7) Prepare integer label mapping for tree models (fit mapping on train only)\n",
    "label_maps = {}\n",
    "X_train_tree = pd.DataFrame(index=X_train_raw.index)\n",
    "X_test_tree  = pd.DataFrame(index=X_test_raw.index)\n",
    "\n",
    "for col in FEATURES:\n",
    "    uniques = X_train_raw[col].unique().tolist()\n",
    "    mapping = {v: i for i, v in enumerate(uniques)}\n",
    "    unknown_idx = len(mapping)\n",
    "    # apply mapping\n",
    "    X_train_tree[col + \"_idx\"] = X_train_raw[col].map(mapping).fillna(unknown_idx).astype(int)\n",
    "    X_test_tree[col + \"_idx\"]  = X_test_raw[col].map(lambda v: mapping.get(v, unknown_idx)).astype(int)\n",
    "    label_maps[col] = {\"mapping\": mapping, \"unknown_index\": unknown_idx}\n",
    "\n",
    "# 8) Train models on the same train split\n",
    "print(\"\\nTraining models on identical train/test split...\")\n",
    "\n",
    "# Logistic Regression (One-Hot input)\n",
    "logreg = LogisticRegression(max_iter=2000, class_weight='balanced', solver='lbfgs')\n",
    "logreg.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Random Forest (integer-coded input)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "rf.fit(X_train_tree, y_train)\n",
    "\n",
    "# LightGBM (integer-coded input)\n",
    "lgbm = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=31, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "lgbm.fit(X_train_tree, y_train)\n",
    "\n",
    "# XGBoost (optional)\n",
    "xgb_model = None\n",
    "if xgb is not None:\n",
    "    try:\n",
    "        xgb_model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "        xgb_model.fit(X_train_tree, y_train, eval_set=[(X_test_tree, y_test)], verbose=False)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: XGBoost training failed:\", e)\n",
    "        xgb_model = None\n",
    "\n",
    "# 9) Evaluate helper\n",
    "def evaluate(name, model, X, y_true, is_prob_model=True):\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1] if is_prob_model and hasattr(model, \"predict_proba\") else None\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_proba) if y_proba is not None else np.nan\n",
    "    cm   = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}  Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}  AUC: {auc:.4f}\")\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    return {\"name\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc, \"cm\": cm, \"proba\": y_proba}\n",
    "\n",
    "results = []\n",
    "results.append(evaluate(\"Logistic Regression\", logreg, X_test_ohe, y_test, is_prob_model=True))\n",
    "results.append(evaluate(\"Random Forest\", rf, X_test_tree, y_test, is_prob_model=True))\n",
    "results.append(evaluate(\"LightGBM\", lgbm, X_test_tree, y_test, is_prob_model=True))\n",
    "if xgb_model is not None:\n",
    "    results.append(evaluate(\"XGBoost\", xgb_model, X_test_tree, y_test, is_prob_model=True))\n",
    "\n",
    "# 10) ROC plot (if probabilities exist)\n",
    "plt.figure(figsize=(8,6))\n",
    "plotted = False\n",
    "for res in results:\n",
    "    proba = res[\"proba\"]\n",
    "    if proba is not None and not np.all(np.isnan(proba)):\n",
    "        fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "        auc_val = roc_auc_score(y_test, proba)\n",
    "        plt.plot(fpr, tpr, label=f\"{res['name']} (AUC={auc_val:.3f})\")\n",
    "        plotted = True\n",
    "if plotted:\n",
    "    plt.plot([0,1],[0,1],\"k--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve - All models (same random split)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"roc_same_split.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved ROC plot -> roc_same_split.png\")\n",
    "else:\n",
    "    print(\"No probability outputs available; skipped ROC plot.\")\n",
    "\n",
    "# 11) Summary table and save\n",
    "summary = pd.DataFrame(results).set_index(\"name\")[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]]\n",
    "print(\"\\nModel comparison (on test set):\")\n",
    "print(summary)\n",
    "summary.to_csv(\"model_comparison_same_split.csv\", index=True)\n",
    "print(\"Saved summary -> model_comparison_same_split.csv\")\n",
    "\n",
    "# 12) Save confusion matrix for Random Forest\n",
    "cm_rf = results[1][\"cm\"]\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_rf, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Delay(0)\",\"On-time(1)\"], yticklabels=[\"Delay(0)\",\"On-time(1)\"], cbar=False)\n",
    "plt.title(\"Random Forest - Confusion Matrix (same split)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rf_confusion_same_split.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved rf_confusion_same_split.png\")\n",
    "\n",
    "# 13) Save feature importances for tree models (they are integer-coded columns)\n",
    "rf_feats = X_train_tree.columns.tolist()\n",
    "imp_df = pd.DataFrame({\"feature\": rf_feats, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending=False)\n",
    "imp_df.to_csv(\"rf_importances_same_split.csv\", index=False)\n",
    "print(\"Saved rf_importances_same_split.csv\")\n",
    "\n",
    "print(\"All done.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
